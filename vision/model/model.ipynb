{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdcdc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que el dataset se puede cargar correctamente\n",
    "from ultralytics.data.utils import check_det_dataset\n",
    "import yaml\n",
    "\n",
    "# Cargar y verificar el archivo de configuración\n",
    "with open(\"larc-2/data_fixed.yaml\", \"r\") as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "    \n",
    "print(\"Configuración del dataset:\")\n",
    "for key, value in data_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Verificar que el dataset se puede cargar\n",
    "try:\n",
    "    dataset_info = check_det_dataset(\"larc-2/data_fixed.yaml\")\n",
    "    print(\"\\n✅ Dataset verificado exitosamente!\")\n",
    "    print(f\"Imágenes de entrenamiento: {len(dataset_info.get('train', []))}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Error verificando dataset: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fbd744-f22b-48e5-b062-aea434aa0046",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from roboflow import Roboflow\n",
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv()\n",
    "print(\"GPU disponible:\", torch.cuda.is_available())\n",
    "\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb71283",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = Roboflow(api_key=os.getenv(\"ROBOFLOW_API_KEY\"))\n",
    "project = rf.workspace(os.getenv(\"ROBOFLOW_WORKSPACE\")).project(os.getenv(\"ROBOFLOW_PROJECT_ID\"))\n",
    "version = project.version(2)\n",
    "dataset = version.download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8a75af-c591-4cf7-88e0-0566fc144658",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the pre-trained YOLOv8m model\n",
    "model = YOLO(\"yolov8m.pt\")\n",
    "\n",
    "# Train the model with the downloaded dataset\n",
    "results = model.train(\n",
    "    data=\"larc-2/data_fixed.yaml\",  # Usar el archivo data.yaml corregido\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=4,\n",
    "    split=0.8,  # Dividir automáticamente: 80% entrenamiento, 20% validación\n",
    "    perspective=0.0005,\n",
    "    scale=0.4,\n",
    "    translate=0.04,\n",
    "    degrees=5,\n",
    "    shear=1,\n",
    "    hsv_s=0.5,\n",
    "    hsv_v=0.3,\n",
    "    flipud=0.2,\n",
    "    patience=15,\n",
    "    save_period=20,\n",
    "    name=\"larc-model\",\n",
    "    project=\"runs/detect\",\n",
    ")\n",
    "\n",
    "# Validate the model trained\n",
    "model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "329f4e78-93f1-4daa-bdf8-7e84b94dafd1",
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/hector/Desktop/LARC_OPEN2025/vision/model/larc-2/train/images/IMG_1925_jpg.rf.801203b3907a7cca6b145ead8c948ea1.jpg: 640x480 1 mature, 12.3ms\n",
      "Speed: 1.7ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Detecciones encontradas: 1\n",
      "Detección 1: mature (confianza: 0.97)\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo entrenado (no el modelo base)\n",
    "model = YOLO(\"runs/detect/larc-model/weights/best.pt\")\n",
    "\n",
    "# Probar el modelo con una imagen del dataset\n",
    "image_path = \"larc-2/train/images/IMG_1925_jpg.rf.801203b3907a7cca6b145ead8c948ea1.jpg\"\n",
    "results = model(image_path)\n",
    "\n",
    "# Mostrar los resultados\n",
    "annotated_img = results[0].plot()\n",
    "\n",
    "# Mostrar la imagen con detecciones\n",
    "cv2.imshow(\"YOLO inference - Modelo Entrenado\", annotated_img)\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Imprimir información de las detecciones\n",
    "print(f\"Detecciones encontradas: {len(results[0].boxes)}\")\n",
    "if len(results[0].boxes) > 0:\n",
    "    for i, box in enumerate(results[0].boxes):\n",
    "        class_id = int(box.cls)\n",
    "        confidence = float(box.conf)\n",
    "        class_name = results[0].names[class_id]\n",
    "        print(f\"Detección {i+1}: {class_name} (confianza: {confidence:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b358a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"runs/detect/larc-model/weights/best.pt\")\n",
    "\n",
    "image_path = \"larc-2/train/images/IMG_1925_jpg.rf.801203b3907a7cca6b145ead8c948ea1.jpg\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
